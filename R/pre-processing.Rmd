---
title: "Pre - Processing"
output: word_document
---

# Objectives
* Filter data
  + Screen patients
  + Drop factors
* Calculate EGFR rate for each patient
* Impute missing values
* Normalize data
  + Box-Cox transformation for continuous variables
  + Convert categorical variables into binary


```{r echo = FALSE, results = 'asis'}
# upload raw data; clinical features located on columns 7 - 2271
rawdata <- read.csv("../data/RedCap.csv")
rawdata <- rawdata[c(2, 12:2271)] # keep patient ID and clinical features

# untargeted CRIC metadata
untarmet <- read.csv("../data/clinical_creatinine_normalized_data/CRIC_clinical_creatinine_normalized_samplemetadata.csv", header=FALSE, stringsAsFactors = FALSE)

```

```{r echo = FALSE, results = 'asis'}
# extract patient IDs from untargeted data
vid <- substr(untarmet$V2,1,7)
pid <- unique(vid)

# remove patients in rawdata who are not represented in untarmet, and vice versa
if (any(!pid %in% rawdata$patientid)) {print("there are patients in the metadata that are not in the raw data")}

no_match <- row.names(rawdata[!rawdata$patientid %in% pid,])
rawdata <- rawdata[-as.integer(no_match),]
if (any(!rawdata$patientid %in% pid)) {print("there are patients in the raw data that are not in the metadata")}   #test

#subset initial visit only
df_init <- data.frame(rawdata$patientid) # include patient id information
df_init <- data.frame(df_init, rawdata[,grepl("v3y0", colnames(rawdata))]) # find all factors from v3y0
```

# Filter patients based on inclusion criteria
Drop patients who have had an amputation, did not give genetic consent, are using SERMS, or who have greater than 20% of their clinical feature data missing.
```{r echo = FALSE, results = 'asis'}
# drop patients who have had an amputation
df_init <- df_init[-grep(1, df_init$amputation_v3y0),]
rawdata <- rawdata[-grep(1, rawdata$amputation_v3y0),]


# drop patients who did not give genetic consent
df_init <- df_init[-grep(0, df_init$genetic_consent_bl_v3y0),]
rawdata <- rawdata[-grep(0, rawdata$genetic_consent_bl_v3y0),]

# drop patients using SERMS
df_init <- df_init[-grep(1, df_init$serms_v3y0),]
rawdata <- rawdata[-grep(1, rawdata$serms_v3y0),]

```

EGFR rate informs inclusion criteria; only include patients who have 4+ EGFR readings
```{r echo = FALSE, results = 'asis'}

# Calculate EGFR rate and variance for each patient
entry <- c(1:6)

#get number of unique visits on file
visits<- unique(substring(names(rawdata)[grep(paste("^egfr_cric", "_v", "[0-9]+", "y", "[0-9]+", sep = ""), names(rawdata))],11))

#init average yearly egfr exponential rate and volatility
Qbar <- rep(0,dim(rawdata)[1])
Qvar <- Qbar

#init valid visit counter
count <- Qbar

#get baseline egfr
Q0 <- rawdata$egfr_cric_v3y0
#get baseline time
t0 <- rawdata$days_thisvisit_v3y0

#loop over visits to calculate egfr return for every year
for (visit in visits[2:length(visits)]){
  #get current year egfr
  Qt <- rawdata[,paste("egfr_cric_",visit,sep = "")]
  #get time this visit
  t <- rawdata[,paste("days_thisvisit_",visit,sep = "")]

  #calculate egfr return in units of per year
  #Qdot <- 365*log(Qt/Q0)/(t-t0)
  #calculate egfr return in units of per visit
  Qdot <- log(Qt/Q0)

  #print(visit)
  #print(Qdot)
  
  #get the valid visit indecies
  vidx <- which(!is.na(Qdot))
  count[vidx] <- count[vidx] + 1 
  
  #accumulate first and second moments
  Qbar[vidx] <- Qbar[vidx]+Qdot[vidx]
  Qvar[vidx] <- Qvar[vidx]+Qdot[vidx]*Qdot[vidx]
    
  #update previous time and egfr
  Q0 <- Qt
  t0 <- t
}

#calculate mean and variance
Qbar <- Qbar/count
Qvar <- Qvar/count - Qbar*Qbar

#update rawdata
rawdata$Qbar <- Qbar
rawdata$Qvar <- Qvar

QQbar<- quantile(rawdata$Qbar,probs = seq(0,1,.25), na.rm = TRUE)
QQvar<- quantile(rawdata$Qvar,probs = seq(0,1,.25), na.rm = TRUE)


#init long form data for egfr with baseline visit
df <- rawdata[1:2]
df$rgroup <- findInterval(rawdata$Qbar, QQbar)
df$vgroup <- findInterval(rawdata$Qvar, QQvar)
df$mu_egfr_rate <- rawdata$Qbar
df$sigma_egfr_rate <-rawdata$Qvar
visit <- visits[1]
df$egfr <- rawdata[,paste("egfr_cric_",visit,sep = "")]
df$year <- 0
#loop over visits
for (i in c(2:length(visits))){
  df2 <- rawdata[1:2]
  df2$rgroup <- findInterval(rawdata$Qbar, QQbar)
  df2$vgroup <- findInterval(rawdata$Qvar, QQvar)
  df2$mu_egfr_rate <- rawdata$Qbar
  df2$sigma_egfr_rate <-rawdata$Qvar
  df2$egfr <- rawdata[,paste("egfr_cric_",visits[i],sep = "")]
  df2$year <- i
  df <- rbind(df,df2)
}

# drop patients with less than 4 readings
egfr_readings <- count + 1

df_init$egfr_readings <- egfr_readings
few_egfr <- as.integer(row.names(df_init[df_init$egfr_readings < 4,]))

df_init <- df_init[!row.names(df_init) %in% few_egfr,]
rawdata <- rawdata[!row.names(rawdata) %in% few_egfr,]




```





Drop features that have been calculated such as survival analyses, were used for screening, are missing more than 20% of entries, etc.
```{r echo = FALSE, results = 'asis'}
#drop features that are not useful in initial data set and in raw data
#inclusion criteria: no amputations, genetic consent given, not taking SERMS
ignore <- c()
# drop features that contain > 20% NA or missing values in the initial data set and record which features they are

for (factor in 1:ncol(df_init)) {
  blanks <- sum(is.na(df_init[,factor])) # number of NA entries
  if (blanks == 0) blanks <-  nrow(df_init[df_init[,factor] == "",]) # number of blank entries
  total <- length(df_init[,factor]) # total number of entries
  if (blanks/total >= .2) { ignore <- c(ignore, factor) } # ignore factor if >= 20% of entries are blank
}

# drop calculated features
# fram
ignore <- c(ignore, grep("fram", names(df_init)))

# survival analysis
ignore <- c(ignore, grep("sa_", names(df_init)))
ignore <- c(ignore, grep("time_", names(df_init)))
ignore <- c(ignore, grep("scr_roche", names(df_init)))

# side by side time
ignore <- c(ignore, grep("side_by_side", names(df_init)))

# drop screening factors (should be the same across the board now)
ignore <- c(ignore, grep("amputation", names(df_init)))
ignore <- c(ignore, grep("genetic_consent", names(df_init)))
ignore <- c(ignore, grep("serms", names(df_init)))

# drop ions
ignore <- c(ignore, grep("ion_", names(df_init)))

# drop certain categorical variables based on distribution
ignore <- c(ignore, grep("albuminuria", names(df_init)))
ignore <- c(ignore, grep("diabetes", names(df_init)))
ignore <- c(ignore, grep("roche", names(df_init)))
ignore <- c(ignore, grep("hibp", names(df_init)))
ignore <- c(ignore, grep("igfr_baseline", names(df_init)))
ignore <- c(ignore, grep("egfr", names(df_init)))
ignore <- c(ignore, grep("esrd", names(df_init)))

# drop u 24h proteins because they are measured in urinary_protein
ignore <- c(ignore, grep("ualbumin", names(df_init)))
ignore <- c(ignore, grep("ucreatinine", names(df_init)))
ignore <- c(ignore, grep("uprotein", names(df_init)))



df_init <- df_init[-ignore]
print(paste0("Drop ", length(ignore), " features."))

```

```{r echo = FALSE, results = 'asis'}

# drop patients with > 20% missing
drop_pat <- c()
for (p in 1:nrow(df_init)) {
  if (sum(is.na(df_init[p,])) / ncol(df_init) > .2) {
    drop_pat <- c(drop_pat, p)
  }
}
if (!is.null(drop_pat)) {
  df_init <- df_init[-drop_pat,]
  rawdata <- rawdata[-drop_pat,]
}
```




```{r echo = FALSE, results = 'asis'}
#drop all features that we dropped from the first visit in all the other visits
ig_raw <- c()

for (f in 1:length(names(df_init)[ignore])) {
  lookfor <- gsub("v3y0", "", names(df_init)[ignore][f])
  ig_raw <- c(ig_raw, grep(lookfor, names(rawdata)))
}
rawdata <- rawdata[-!is.na(ig_raw)]
```

# Summary of remaining features:
```{r echo = FALSE, results = 'asis'}
library(knitr)

cont_df <- data.frame(matrix(nrow = nrow(df_init), ncol= 4, 0))
colnames(cont_df) <- c("name", "n", "mean", "std")
i <- 1
for (factor in 2:ncol(df_init)) {
  if (length(table(df_init[,factor])) > 10) {  # factor is continuous
    cont_df$name[i] <- colnames(df_init)[factor]
    cont_df$n[i] <- sum(!is.na(df_init[,factor]))
    cont_df$mean[i] <- mean(df_init[,factor], na.rm = TRUE)
    cont_df$std[i] <- sd(df_init[,factor], na.rm = TRUE)
    i <- i + 1
  } else { # factor is categorical
    cat_summary <- as.data.frame(table(df_init[,factor], useNA = "always"))
    cat_summary$Percentage <- (cat_summary$Freq*100)/total
    print(kable(cat_summary, caption = colnames(df_init)[factor]))
  }
}
cont_df <- cont_df[cont_df$name != 0,]
print(kable(cont_df, caption = "continuous variable summary"))

```





```{r echo = FALSE, results = 'asis', message=FALSE}
# Impute missing values using k-nearest neighbors
# original data still exists as df_init

library(DMwR)

# make sure categorical variables are defined as factors
for (factor in 1:ncol(df_init)) {
  if (length(table(df_init[,factor])) < 10) {
    df_init[,factor] <- as.factor(df_init[,factor])
  }
}

res <- knnImputation(df_init, k = 10, meth = "median", scale = F)

```



```{r echo = FALSE, results = 'asis'}
#Turn all categorical variables into binary variables

n_factors <- length(res)
colnames <- colnames(res)
for (factor in 2:ncol(res)) {                                                       # for each factor
  if ((length(table(res[,factor])) < 10) && (length(table(res[,factor])) > 2)) {    # if factor is categorical and not already binary
    new_names <- levels(as.data.frame(table(res[,factor]))$Var1)                    # save category names as new_names
    for (name in 1:length(new_names)) {                                             # for each of these category names
      res[,n_factors + 1] <- as.integer(grepl(name,res[,factor]))                   # add a column to res with binary form of the cat
      colnames <- c(colnames, paste0(colnames[factor], "_", name))                  # update df column names
      n_factors <- n_factors + 1                                                    # update number of factors in res
    }
    res <- res[-factor]                                                             # remove original categorical factor
    colnames <- colnames[-factor]                                                   # update colnames
    n_factors <- n_factors - 1                                                      # update number of factors in res
  }
}
colnames(res) <- colnames


# do this for the initial data too which will remain un imputed
n_factors <- length(df_init)
colnames <- colnames(df_init)
for (factor in 2:ncol(df_init)) {                                                       # for each factor
  if ((length(table(df_init[,factor])) < 10) && (length(table(df_init[,factor])) > 2)) {    # if factor is categorical and not already binary
    new_names <- levels(as.data.frame(table(df_init[,factor]))$Var1)                    # save category names as new_names
    for (name in 1:length(new_names)) {                                             # for each of these category names
      df_init[,n_factors + 1] <- as.integer(grepl(name,df_init[,factor]))                   # add a column to df_init with binary form of the cat
      colnames <- c(colnames, paste0(colnames[factor], "_", name))                  # update df column names
      n_factors <- n_factors + 1                                                    # update number of factors in df_init
    }
    df_init <- df_init[-factor]                                                             # remove original categorical factor
    colnames <- colnames[-factor]                                                   # update colnames
    n_factors <- n_factors - 1                                                      # update number of factors in df_init
  }
}
colnames(df_init) <- colnames

no_impute <- df_init

# add egfr col
egfr_v0 <- df[df$year == 0,]
egfr_v0 <- egfr_v0[!row.names(egfr_v0) %in% few_egfr,]
no_impute$egfr <- egfr_v0$mu_egfr_rate

# remove all rows with NA
no_impute <- no_impute[complete.cases(no_impute),]

# extract no_impute_egfr
no_impute_egfr <- no_impute$egfr
no_impute <- no_impute[-66]


```


```{r echo = FALSE, results = 'asis', message = FALSE}
#Normalize continuous data with box-cox transformation
transform_continuous_data <- function(df, description){

  library(car)
  
  # if lambda needed to transform data is too high and there is not a significan change in normality, do not transform the data
  summary <- data.frame("init" = c(1:200), "name" = 0, "initial_rsquared" = 0, "transformed_rsquared" = 0, "lambda" = 0, "transformed" = 1, "n_missing" = 0)
  summary <- summary[-c(1)]
  line <- 1
  
  biglambda <- c()
  untransformed <- c()
  for (factor in 2:ncol(df)) {
    if (length(table(df[,factor])) > 10) {  # factor is continuous
      my_object <- df[,factor]
      name <- colnames(df)[factor]
          
      # before transformation
  
      qq_before <- qqnorm(my_object, ylab=name, main = paste0(name, " before transformation"), plot.it = FALSE)
      r_before <- cor(qq_before$x,qq_before$y)
  
      bc_dfult <- boxCox(my_object ~ 1, plotit = F, lambda = seq(-5,5,.1), eps = 0, family = "yjPower")
      bc_df <- data.frame(bc_dfult$x, bc_dfult$y)
      lambda <- bc_df[with(bc_df, order(-bc_df$bc_dfult.y)),][1,1]
          
      # after transformation
      if (lambda == 0) {transformed <- log(my_object)}
      if (lambda != 0) {transformed <- (my_object ^ lambda -1) / lambda}
            
      qq_after <- qqnorm(transformed, ylab=name, main = paste0(name, " after transformation"), plot.it = FALSE)
      r_after <- cor(qq_after$x,qq_after$y, use = "na.or.complete")
  
      if ((lambda > 1) && ((r_after - r_before)/r_before < .05)) {   # if lambda > 1 but there is no significant shift towards normal, use original data
        transformed <- my_object
        summary$transformed[line] <- 0
        untransformed <- c(untransformed, name)           # note exceptions
      } else {
        df[,factor] <- transformed 
        if (lambda> 1) {biglambda <- c(biglambda, name)} #note big lambdas
      }
          
      summary$name[line] <- name
      summary$initial_rsquared[line] <- r_before*r_before
      summary$transformed_rsquared[line] <- r_after*r_after
      summary$lambda[line] <- lambda
      summary$n_missing[line] <- nrow(df) - length(transformed)
      line <- line + 1
    }
  }
  
  summary <- summary[summary$name != 0,]
  
  # note these exceptions
  print(kable(summary, label = description))
  print("The following continuous factors were not transformed because transformation did not significantly shift them towards normality: ")
  print(untransformed)
  
}
```


```{r echo = FALSE, results = "asis"}
# transform the data

transform_continuous_data(res, "imputed data")
transform_continuous_data(no_impute, "non imputed data")

```




```{r echo = FALSE, results = 'asis'}
#add egfr vals to result
egfr_v0 <- df[df$year == 0,]
egfr_v0 <- egfr_v0[-few_egfr,]

res$mu_egfr <- egfr_v0$mu_egfr_rate
res$sigma_egfr <- egfr_v0$sigma_egfr_rate
res$r_group <- egfr_v0$rgroup
res$v_group <- egfr_v0$vgroup
res$patientID <- rawdata$patientid

# add egfr vals to no_impute
no_impute$mu_egfr <- no_impute_egfr

```

```{r echo = FALSE, results = 'asis'}
# based on clinical features, make list of all patient IDs that were included
# use included patients to filter untargeted data

# load untargeted cric data
untar <- read.csv("../data/clinical_creatinine_normalized_data/CRIC_clinical_creatinine_normalized_data.csv", header=FALSE)
incl_patients <- res$rawdata.patientid

t_untar <- as.data.frame(t(untar))

untarmet$vid <- vid
keep_tar_rows <- as.integer(row.names(untarmet[as.integer(untarmet$vid) %in% incl_patients,]))

untarmet <- untarmet[keep_tar_rows,]
t_untar <- t_untar[keep_tar_rows,]

# save untargeted data filtered by patient
t_t_untar <- as.data.frame(t(t_untar))
write.csv(t_t_untar, "../data/clinical_creatinine_normalized_data/cric_normalized_data_filteredByPatient.csv")

```



```{r echo = FALSE, results = 'asis'}
#save data
write.csv(res, "../data/preprocessingresults.csv", row.names = FALSE)
write.csv(df, "../data/egfr_results.csv", row.names = FALSE)
write.csv(no_impute, "../data/nonimputed_preprocessingresults.csv", row.names = FALSE)

```